{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torchmetrics import Dice\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import albumentations as A\n",
    "import torchvision.transforms.functional as TF\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from path import Path\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.set_device(0)\n",
    "\n",
    "# print(device)\n",
    "# print(torch.cuda.current_device())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:\n",
      "Train images: 3813\t Train masks: 3813\n",
      "Val images: 195\t Val masks: 195\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE= 1e-3\n",
    "BATCH_SIZE= 8\n",
    "NUM_EPOCHS= 10\n",
    "NUM_WORKERS= 0\n",
    "\n",
    "IMAGE_HEIGHT= 512\n",
    "IMAGE_WIDTH= 416\n",
    "PIN_MEMORY= True\n",
    "LOAD_MODEL= False\n",
    "\n",
    "# num_block= [3, 4, 6, 3];\n",
    "features_depth= [64, 128, 256, 512]\n",
    "input_channel= 1 \n",
    "num_classes= 3\n",
    "\n",
    "model_category = 'segAN'\n",
    "checkpoint_path = 'segAN.pth'\n",
    "# training_checkpoint = 'training_checkpoint.pth'\n",
    "\n",
    "TRAIN_IMG_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/train_f/*\"))\n",
    "TRAIN_MASK_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/train_m/*\"))\n",
    "\n",
    "VAL_IMG_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/val_f/*\"))\n",
    "VAL_MASK_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/val_m/*\"))\n",
    "\n",
    "data_str = f\"Dataset Size:\\nTrain images: {len(TRAIN_IMG_DIR)}\\t Train masks: {len(TRAIN_MASK_DIR)}\"\n",
    "print(data_str)\n",
    "\n",
    "data_str = f\"Val images: {len(VAL_IMG_DIR)}\\t Val masks: {len(VAL_MASK_DIR)}\"\n",
    "print(data_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EchoDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "        image = image/image.max()\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)        \n",
    "        mask = cv2.resize(mask, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "        masks = [(mask==c) for c in range(3)]\n",
    "        mask = np.stack(masks, axis=0)\n",
    "        mask = mask.astype(np.float32)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentation= self.transform(image= image, mask= mask)\n",
    "            image = augmentation['image']\n",
    "            mask = augmentation['mask']\n",
    "\n",
    "            # image = np.transpose(image, (1,2,0)).to(torch.float32)\n",
    "            # mask = mask.to(torch.float32)\n",
    "\n",
    "        return image, mask, self.images_path[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomGamma(gamma_limit= 70,p=0.6)\n",
    "\n",
    "])\n",
    "\n",
    "def get_train_data(train_img_dir, train_mask_dir, val_img_dir, val_mask_dir, batch_size, train_transform, val_transform, num_workers, pin_memory):\n",
    "    train_ds= EchoDataset(train_img_dir, train_mask_dir, train_transform)\n",
    "    train_dataloader= DataLoader(train_ds, batch_size=batch_size,\n",
    "                                 shuffle=True, \n",
    "                                 num_workers=num_workers,\n",
    "                                 pin_memory=pin_memory)\n",
    "    val_ds= EchoDataset(val_img_dir, val_mask_dir, val_transform)\n",
    "    val_dataloader= DataLoader(val_ds, batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               num_workers=num_workers,\n",
    "                               pin_memory=pin_memory)\n",
    "\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "def get_test_data(test_img_dir, test_mask_dir, batch_size, test_transform, num_workers, pin_memory):\n",
    "    test_ds= EchoDataset(test_img_dir, test_mask_dir, test_transform)\n",
    "    test_dataloader= DataLoader(test_ds, batch_size=batch_size,\n",
    "                                shuffle= False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=pin_memory) \n",
    "    return test_dataloader\n",
    "\n",
    "\n",
    "# train_ds= EchoDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform)\n",
    "# print(ds[1][0].dtype)\n",
    "train_dataloader, val_dataloader = get_train_data(train_img_dir= TRAIN_IMG_DIR, train_mask_dir= TRAIN_MASK_DIR, \n",
    "                                                  val_img_dir= VAL_IMG_DIR, val_mask_dir= VAL_MASK_DIR, \n",
    "                                                  train_transform=None, val_transform=None,\n",
    "                                                  batch_size= BATCH_SIZE, \n",
    "                                                  num_workers= NUM_WORKERS, \n",
    "                                                  pin_memory= PIN_MEMORY)\n",
    "\n",
    "len(train_dataloader)\n",
    "\n",
    "                        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el1: torch.Size([8, 64, 256, 208])\n",
      "el2: torch.Size([8, 128, 128, 104])\n",
      "el3: torch.Size([8, 256, 64, 52])\n",
      "el4: torch.Size([8, 512, 32, 26])\n",
      "dl1: torch.Size([8, 256, 64, 52])\n",
      "dl2: torch.Size([8, 128, 128, 104])\n",
      "dl3: torch.Size([8, 64, 256, 208])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6109, 0.5351, 0.4678,  ..., 0.5460, 0.5013, 0.4615],\n",
       "          [0.5768, 0.5513, 0.5992,  ..., 0.4870, 0.5765, 0.5494],\n",
       "          [0.5357, 0.5165, 0.5681,  ..., 0.4680, 0.4671, 0.4106],\n",
       "          ...,\n",
       "          [0.6031, 0.5994, 0.5855,  ..., 0.4698, 0.6346, 0.5408],\n",
       "          [0.5060, 0.4561, 0.5456,  ..., 0.5960, 0.4277, 0.5294],\n",
       "          [0.4877, 0.5053, 0.6266,  ..., 0.6454, 0.5981, 0.4790]],\n",
       "\n",
       "         [[0.6293, 0.5737, 0.5060,  ..., 0.5704, 0.5511, 0.5324],\n",
       "          [0.5827, 0.5712, 0.6742,  ..., 0.5261, 0.6272, 0.5715],\n",
       "          [0.5436, 0.5760, 0.6069,  ..., 0.5521, 0.5060, 0.5137],\n",
       "          ...,\n",
       "          [0.6239, 0.5934, 0.6380,  ..., 0.5347, 0.6877, 0.5692],\n",
       "          [0.5990, 0.5556, 0.5656,  ..., 0.6222, 0.5102, 0.6197],\n",
       "          [0.5584, 0.5563, 0.6354,  ..., 0.6179, 0.5953, 0.5399]],\n",
       "\n",
       "         [[0.4230, 0.4105, 0.4060,  ..., 0.3924, 0.4266, 0.4423],\n",
       "          [0.3758, 0.4125, 0.4899,  ..., 0.4097, 0.4342, 0.4200],\n",
       "          [0.3962, 0.4582, 0.4395,  ..., 0.4550, 0.4246, 0.4556],\n",
       "          ...,\n",
       "          [0.3709, 0.3889, 0.3960,  ..., 0.4568, 0.4161, 0.4267],\n",
       "          [0.5106, 0.4715, 0.4305,  ..., 0.4550, 0.4737, 0.4830],\n",
       "          [0.4251, 0.4415, 0.3749,  ..., 0.3469, 0.3731, 0.4222]]],\n",
       "\n",
       "\n",
       "        [[[0.6222, 0.6119, 0.4771,  ..., 0.5527, 0.3667, 0.5052],\n",
       "          [0.5334, 0.5252, 0.7394,  ..., 0.5170, 0.5886, 0.4582],\n",
       "          [0.4965, 0.4946, 0.6732,  ..., 0.5113, 0.3668, 0.5576],\n",
       "          ...,\n",
       "          [0.5291, 0.5013, 0.5643,  ..., 0.4330, 0.4580, 0.5276],\n",
       "          [0.5075, 0.4913, 0.6128,  ..., 0.6157, 0.4331, 0.5289],\n",
       "          [0.5564, 0.5392, 0.5964,  ..., 0.5296, 0.5972, 0.5255]],\n",
       "\n",
       "         [[0.6420, 0.6113, 0.5053,  ..., 0.5798, 0.4375, 0.5724],\n",
       "          [0.5743, 0.5625, 0.7501,  ..., 0.5375, 0.6814, 0.4884],\n",
       "          [0.5139, 0.5652, 0.6693,  ..., 0.5979, 0.4686, 0.6079],\n",
       "          ...,\n",
       "          [0.5930, 0.5264, 0.6204,  ..., 0.5179, 0.5785, 0.5851],\n",
       "          [0.5605, 0.5703, 0.5976,  ..., 0.6178, 0.4977, 0.5755],\n",
       "          [0.5883, 0.5723, 0.6148,  ..., 0.5808, 0.6042, 0.5658]],\n",
       "\n",
       "         [[0.4279, 0.4034, 0.4143,  ..., 0.4000, 0.4235, 0.4322],\n",
       "          [0.3827, 0.4623, 0.4724,  ..., 0.4612, 0.4767, 0.3773],\n",
       "          [0.4017, 0.4810, 0.4268,  ..., 0.4589, 0.4651, 0.4306],\n",
       "          ...,\n",
       "          [0.4231, 0.4353, 0.4261,  ..., 0.4639, 0.4574, 0.4899],\n",
       "          [0.4684, 0.4612, 0.3794,  ..., 0.4097, 0.4374, 0.4398],\n",
       "          [0.4009, 0.4098, 0.3887,  ..., 0.4383, 0.3935, 0.4174]]],\n",
       "\n",
       "\n",
       "        [[[0.5460, 0.5324, 0.5491,  ..., 0.4336, 0.4266, 0.4395],\n",
       "          [0.5115, 0.4640, 0.5889,  ..., 0.5150, 0.6552, 0.5806],\n",
       "          [0.5573, 0.5598, 0.4938,  ..., 0.4955, 0.4614, 0.5276],\n",
       "          ...,\n",
       "          [0.5608, 0.5710, 0.6327,  ..., 0.5378, 0.6053, 0.5933],\n",
       "          [0.5668, 0.4412, 0.5426,  ..., 0.7697, 0.6627, 0.4409],\n",
       "          [0.5120, 0.5528, 0.6153,  ..., 0.4678, 0.4491, 0.5110]],\n",
       "\n",
       "         [[0.5850, 0.5782, 0.5694,  ..., 0.4879, 0.4938, 0.5010],\n",
       "          [0.5862, 0.5002, 0.6237,  ..., 0.5455, 0.6905, 0.5858],\n",
       "          [0.5849, 0.6318, 0.5421,  ..., 0.5774, 0.5118, 0.6173],\n",
       "          ...,\n",
       "          [0.6174, 0.6052, 0.6533,  ..., 0.5830, 0.6763, 0.6243],\n",
       "          [0.5636, 0.5420, 0.5867,  ..., 0.7404, 0.6651, 0.5101],\n",
       "          [0.5727, 0.5692, 0.6216,  ..., 0.5199, 0.5010, 0.5512]],\n",
       "\n",
       "         [[0.4283, 0.4290, 0.4231,  ..., 0.3747, 0.4235, 0.4134],\n",
       "          [0.4360, 0.4112, 0.4052,  ..., 0.4239, 0.4122, 0.3863],\n",
       "          [0.4328, 0.5063, 0.4127,  ..., 0.4805, 0.4328, 0.4993],\n",
       "          ...,\n",
       "          [0.4129, 0.4501, 0.4172,  ..., 0.4219, 0.4330, 0.4795],\n",
       "          [0.4019, 0.5009, 0.4663,  ..., 0.3961, 0.4645, 0.4292],\n",
       "          [0.4184, 0.4120, 0.3842,  ..., 0.4155, 0.4005, 0.4456]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.6195, 0.6130, 0.6264,  ..., 0.6462, 0.4804, 0.4478],\n",
       "          [0.5054, 0.3497, 0.6154,  ..., 0.5234, 0.5540, 0.5585],\n",
       "          [0.4762, 0.6124, 0.6348,  ..., 0.4643, 0.4658, 0.5728],\n",
       "          ...,\n",
       "          [0.5451, 0.6278, 0.6030,  ..., 0.4563, 0.6070, 0.5942],\n",
       "          [0.5797, 0.5521, 0.5644,  ..., 0.5737, 0.4847, 0.4857],\n",
       "          [0.5240, 0.5870, 0.6459,  ..., 0.5940, 0.5869, 0.4976]],\n",
       "\n",
       "         [[0.6149, 0.6163, 0.6037,  ..., 0.6470, 0.5314, 0.5121],\n",
       "          [0.5850, 0.4404, 0.6763,  ..., 0.5368, 0.6528, 0.6021],\n",
       "          [0.4961, 0.6050, 0.6211,  ..., 0.5269, 0.5169, 0.6358],\n",
       "          ...,\n",
       "          [0.5627, 0.6130, 0.6427,  ..., 0.5034, 0.6632, 0.6054],\n",
       "          [0.5861, 0.6194, 0.6016,  ..., 0.5933, 0.5499, 0.5543],\n",
       "          [0.5763, 0.5560, 0.6546,  ..., 0.6009, 0.5915, 0.5546]],\n",
       "\n",
       "         [[0.3828, 0.3845, 0.3780,  ..., 0.3980, 0.4017, 0.4169],\n",
       "          [0.4494, 0.4537, 0.4848,  ..., 0.4133, 0.4860, 0.4588],\n",
       "          [0.3738, 0.4071, 0.3485,  ..., 0.4661, 0.4703, 0.4864],\n",
       "          ...,\n",
       "          [0.3587, 0.4063, 0.4252,  ..., 0.4271, 0.4296, 0.4233],\n",
       "          [0.4150, 0.5057, 0.4694,  ..., 0.4580, 0.4267, 0.4663],\n",
       "          [0.4041, 0.3830, 0.4116,  ..., 0.4126, 0.3727, 0.4490]]],\n",
       "\n",
       "\n",
       "        [[[0.5759, 0.5024, 0.5435,  ..., 0.5870, 0.5216, 0.4526],\n",
       "          [0.4279, 0.4771, 0.5065,  ..., 0.4249, 0.5442, 0.5378],\n",
       "          [0.4351, 0.6620, 0.5716,  ..., 0.4698, 0.4616, 0.4819],\n",
       "          ...,\n",
       "          [0.5855, 0.5548, 0.4612,  ..., 0.4331, 0.5085, 0.6028],\n",
       "          [0.6317, 0.5914, 0.3655,  ..., 0.4766, 0.4395, 0.5210],\n",
       "          [0.6177, 0.4779, 0.5577,  ..., 0.5525, 0.5844, 0.4847]],\n",
       "\n",
       "         [[0.6102, 0.5346, 0.5510,  ..., 0.6077, 0.5634, 0.5089],\n",
       "          [0.5066, 0.5741, 0.5942,  ..., 0.4794, 0.6331, 0.5816],\n",
       "          [0.4732, 0.6453, 0.5677,  ..., 0.5343, 0.5399, 0.5569],\n",
       "          ...,\n",
       "          [0.5987, 0.5740, 0.5617,  ..., 0.4686, 0.5828, 0.6255],\n",
       "          [0.6388, 0.6554, 0.4559,  ..., 0.5451, 0.5219, 0.5689],\n",
       "          [0.6325, 0.5059, 0.6096,  ..., 0.5998, 0.5990, 0.5274]],\n",
       "\n",
       "         [[0.4160, 0.3866, 0.3892,  ..., 0.3962, 0.4035, 0.3986],\n",
       "          [0.4070, 0.5246, 0.4804,  ..., 0.3982, 0.4265, 0.4495],\n",
       "          [0.4056, 0.4013, 0.3992,  ..., 0.3931, 0.4443, 0.4635],\n",
       "          ...,\n",
       "          [0.4008, 0.4016, 0.4065,  ..., 0.3916, 0.4373, 0.4288],\n",
       "          [0.4699, 0.4957, 0.4705,  ..., 0.4771, 0.4634, 0.4272],\n",
       "          [0.4038, 0.3924, 0.4109,  ..., 0.4497, 0.3803, 0.4109]]],\n",
       "\n",
       "\n",
       "        [[[0.5818, 0.6009, 0.4685,  ..., 0.6581, 0.4554, 0.5302],\n",
       "          [0.5363, 0.5254, 0.5508,  ..., 0.4351, 0.6581, 0.4661],\n",
       "          [0.5307, 0.5552, 0.5393,  ..., 0.3970, 0.4525, 0.4792],\n",
       "          ...,\n",
       "          [0.4220, 0.5491, 0.6849,  ..., 0.4656, 0.5978, 0.5976],\n",
       "          [0.4770, 0.5749, 0.6116,  ..., 0.5176, 0.5605, 0.5258],\n",
       "          [0.5365, 0.4393, 0.6376,  ..., 0.5323, 0.5681, 0.5355]],\n",
       "\n",
       "         [[0.6106, 0.6123, 0.5047,  ..., 0.6572, 0.5208, 0.5713],\n",
       "          [0.5861, 0.5640, 0.6542,  ..., 0.4552, 0.6900, 0.5449],\n",
       "          [0.5499, 0.5901, 0.5539,  ..., 0.4819, 0.5063, 0.5590],\n",
       "          ...,\n",
       "          [0.5358, 0.5568, 0.6922,  ..., 0.5109, 0.6265, 0.6086],\n",
       "          [0.5495, 0.6212, 0.5762,  ..., 0.5880, 0.5640, 0.5901],\n",
       "          [0.5844, 0.5138, 0.6476,  ..., 0.5697, 0.5769, 0.5489]],\n",
       "\n",
       "         [[0.4279, 0.3958, 0.3782,  ..., 0.3914, 0.4228, 0.4185],\n",
       "          [0.4084, 0.4570, 0.5231,  ..., 0.3981, 0.4213, 0.4715],\n",
       "          [0.4248, 0.4757, 0.3993,  ..., 0.4436, 0.4096, 0.4799],\n",
       "          ...,\n",
       "          [0.4343, 0.4351, 0.3898,  ..., 0.4188, 0.3689, 0.4333],\n",
       "          [0.4852, 0.4427, 0.3513,  ..., 0.4561, 0.3889, 0.4820],\n",
       "          [0.4164, 0.4483, 0.4142,  ..., 0.4307, 0.3773, 0.4026]]]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class down_conv(nn.Module):\n",
    "    \"\"\" Down convolution with a kernel size of 4x4 and optional batch normalization.\n",
    "    Args:\n",
    "    in_c : int\n",
    "    out_c: int\n",
    "    stride: int\n",
    "    batch_normalization: bool\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, batch_normalization=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv= nn.Conv2d(in_c, out_c, kernel_size=4, stride=2, padding=1)\n",
    "        if batch_normalization:\n",
    "            self.bn= nn.BatchNorm2d(out_c)\n",
    "        else: \n",
    "            self.bn = None\n",
    "        self.relu= nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.conv(x)\n",
    "        if self.bn:\n",
    "            x= self.bn(x)\n",
    "        x= self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.upsample= nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        # self.conv= nn.Conv2d(in_c+in_c, out_c, kernel_size=3, stride=1)\n",
    "        self.conv= nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn= nn.BatchNorm2d(out_c)\n",
    "        self.relu= nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x= torch.cat([x, skip], axis=1)\n",
    "        x= self.upsample(x)\n",
    "        # print(x.shape)\n",
    "        x= self.conv(x)\n",
    "        x= self.bn(x)\n",
    "        x= self.relu(x)\n",
    "        return x\n",
    "\n",
    "class final_conv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.upsample= nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv= nn.Conv2d(out_c, out_c, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= self.upsample(x)\n",
    "        x= self.conv(x)\n",
    "        # need to add sigmoid?\n",
    "        return x\n",
    "\n",
    "class segmentor(nn.Module):\n",
    "    def __init__(self, num_classes, filter_size= [64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.encoder1= down_conv(1, filter_size[0], batch_normalization=False) # 1 -> 64\n",
    "        self.encoder2= down_conv(filter_size[0], filter_size[1]) # 64 -> 128\n",
    "        self.encoder3= down_conv(filter_size[1], filter_size[2]) # 128 -> 256\n",
    "        self.encoder4= down_conv(filter_size[2], filter_size[3]) # 256 -> 512\n",
    "\n",
    "        self.decoder1= up_conv(filter_size[3], filter_size[2]) # 512 -> 256\n",
    "        self.decoder2= up_conv(filter_size[2] + filter_size[2], filter_size[1]) # (256+256) -> 128 (double the initial size because of concatenation)\n",
    "        self.decoder3= up_conv(filter_size[1] + filter_size[1], filter_size[0]) # (128+128) -> 64\n",
    "\n",
    "        self.final_conv= final_conv(filter_size[0] + filter_size[0], 3) # (64+64) -> 3\n",
    "\n",
    "        self.output= nn.Conv2d(3, num_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        el1= self.encoder1(x)\n",
    "        print(\"el1:\" ,el1.shape)\n",
    "        el2= self.encoder2(el1)\n",
    "        print(\"el2:\" ,el2.shape)\n",
    "        el3= self.encoder3(el2)\n",
    "        print(\"el3:\" ,el3.shape)\n",
    "        el4= self.encoder4(el3)\n",
    "        print(\"el4:\" ,el4.shape)\n",
    "\n",
    "        dl1= self.decoder1(el4)\n",
    "        print(\"dl1:\" ,dl1.shape)\n",
    "        # print(\"cat:\", torch.cat([dl1, el3], axis=1).shape)\n",
    "        dl2= self.decoder2(torch.cat([dl1, el3], axis=1))\n",
    "        print(\"dl2:\" ,dl2.shape)\n",
    "        dl3= self.decoder3(torch.cat([dl2, el2], axis=1))\n",
    "        print(\"dl3:\" ,dl3.shape)\n",
    "\n",
    "        dl4= self.final_conv(torch.cat([dl3, el1], axis=1))\n",
    "\n",
    "        output= self.output(dl4)\n",
    "\n",
    "        return torch.sigmoid(output)\n",
    "\n",
    "class critic(nn.Module):\n",
    "    def __init__(self, input_c, filter_size=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1= down_conv(input_c, filter_size[0], batch_normalization=False)\n",
    "        self.conv2= down_conv(filter_size[0], filter_size[1])\n",
    "        self.conv3= down_conv(filter_size[1], filter_size[2])\n",
    "        self.conv4= down_conv(filter_size[2], filter_size[3])\n",
    "\n",
    "        self.conv5= up_conv(filter_size[3], filter_size[2])\n",
    "        self.conv6= up_conv(filter_size[2], filter_size[1])\n",
    "        self.conv7= up_conv(filter_size[1], filter_size[0])\n",
    "\n",
    "        self.conv= final_conv(filter_size[0], input_c)\n",
    "\n",
    "\n",
    "    def forward(self, pred, true, ground_truth):\n",
    "        masked_pred= pred*true # masking the predicted image with the true image\n",
    "        masked_truth= ground_truth*true # masking the ground truth with the true image\n",
    "        c1_pred= self.conv1(masked_pred) # level 1\n",
    "        c2_pred= self.conv2(c1_pred) # level 2\n",
    "        c3_pred= self.conv3(c2_pred) # level 3\n",
    "\n",
    "        c1_gt= self.conv1(masked_truth)\n",
    "        c2_gt= self.conv2(c1_gt)\n",
    "        c3_gt= self.conv3(c2_gt)\n",
    "\n",
    "        c= loss(masked_pred, masked_truth)\n",
    "        c1= loss(c1_pred, c1_gt)\n",
    "        c2= loss(c2_pred, c2_gt)\n",
    "        c3= loss(c3_pred, c3_gt)    \n",
    "        # print(c.shape)\n",
    "        # print(c1.shape)\n",
    "        # print(c2.shape)\n",
    "        # print(c3.shape)\n",
    "\n",
    "\n",
    "        l_mae= torch.cat([c, c1, c2, c3], axis=1).mean(dim=1)\n",
    "\n",
    "        return l_mae\n",
    "    \n",
    "def loss(pred, target):\n",
    "    loss1= torch.abs(pred-target).mean(dim=[1,2,3])\n",
    "    return loss1.unsqueeze(dim=1)\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    def __init__(self, num_classes, lr=0.0002):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.segmentor= segmentor(self.hparams.num_classes)\n",
    "        self.critic = critic(self.hparams.num_classes)\n",
    "        self.automatic_optimization = False\n",
    "        \n",
    "        self.validation_step_dice = []\n",
    "        self.validation_step_bce = []\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.segmentor(z)\n",
    "    \n",
    "    def adversarial_loss(self, l_mae):\n",
    "        return l_mae.mean()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "    \n",
    "        true_imgs, gt, _= batch\n",
    "        opt_c0, opt_s= self.optimizers()\n",
    "\n",
    "        # train the critic\n",
    "        pred_imgs= self(true_imgs).detach()\n",
    "        self.toggle_optimizer(opt_c0)\n",
    "        lmae_c0= self.critic(pred_imgs, true_imgs, gt)\n",
    "        c_loss= self.adversarial_loss(lmae_c0)\n",
    "        self.manual_backward(c_loss)\n",
    "        self.log(\"c0_loss\", c_loss, prog_bar=True)\n",
    "        opt_c0.step()\n",
    "        opt_c0.zero_grad()\n",
    "        self.untoggle_optimizer(opt_c0)\n",
    "\n",
    "        # train the segmentor\n",
    "        self.toggle_optimizer(opt_s)\n",
    "        pred_imgs= self(true_imgs)\n",
    "        lmae_s= self.critic(pred_imgs, true_imgs, gt)\n",
    "        s_loss= self.adversarial_loss(lmae_s)\n",
    "        # print(s_loss)\n",
    "        self.log(\"s_loss\", s_loss, prog_bar=True)\n",
    "        self.manual_backward(s_loss)\n",
    "        opt_s.step()\n",
    "        opt_s.zero_grad()\n",
    "        self.untoggle_optimizer(opt_s)\n",
    "\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = self.hparams.lr\n",
    "\n",
    "        opt_s= torch.optim.Adam(self.segmentor.parameters(), lr=lr)\n",
    "        opt_c0= torch.optim.Adam(self.critic.parameters(), lr=lr)\n",
    "\n",
    "        return [opt_c0, opt_s], []\n",
    "\n",
    "    def validation_step(self, batch, batch_index):\n",
    "        true_imgs, gt, _= batch\n",
    "        pred_imgs=self(true_imgs)\n",
    "\n",
    "        dice_score= dice_loss(pred_imgs, gt)\n",
    "        bce_loss= nn.BCELoss()(pred_imgs, gt)\n",
    "\n",
    "        self.validation_step_dice.append(dice_score.item())\n",
    "        self.validation_step_bce.append(bce_loss.item())\n",
    "        # val_loss= self.adversarial_loss(val_lmae)\n",
    "    \n",
    "    # def test_step(self, batch, batch_index):\n",
    "        # true_imgs, gt, files= batch\n",
    "\n",
    "        \n",
    "    # def on_train_epoch_end(self):\n",
    "        # print('\\n')\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        dice_score= np.mean(self.validation_step_dice)\n",
    "        bce_loss= np.mean(self.validation_step_bce)\n",
    "        print(\"\\nvalidation dice loss in epoch {}: {}\".format(self.current_epoch, dice_score))\n",
    "        print(\"validation bce loss in epoch {}: {}\".format(self.current_epoch, bce_loss))\n",
    "        self.log(\"dice loss\", dice_score)\n",
    "        self.log(\"bce\", bce_loss)\n",
    "        self.validation_step_dice.clear()\n",
    "        self.validation_step_bce.clear()\n",
    "        \n",
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    # print(intersection.shape)\n",
    "    dice = 1-((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth))\n",
    "    \n",
    "    return dice.mean()\n",
    "        \n",
    "x= torch.randn((8,2,20,20))\n",
    "y= torch.randn((8,1,512,416))\n",
    "z= torch.randn((8,1,228,228))\n",
    "\n",
    "segmentor(3)(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | segmentor | segmentor | 4.4 M \n",
      "1 | critic    | critic    | 4.2 M \n",
      "----------------------------------------\n",
      "8.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 M     Total params\n",
      "34.436    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 21.94it/s]\n",
      "validation dice loss in epoch 0: 0.6841183006763458\n",
      "validation bce loss in epoch 0: 0.6177056729793549\n",
      "Epoch 0: 100%|██████████| 477/477 [01:12<00:00,  6.62it/s, v_num=86, c0_loss=0.00619, s_loss=0.0062] \n",
      "validation dice loss in epoch 0: 0.6965522766113281\n",
      "validation bce loss in epoch 0: 0.4752276623249054\n",
      "Epoch 1: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.00596, s_loss=0.00594]\n",
      "validation dice loss in epoch 1: 0.7061354374885559\n",
      "validation bce loss in epoch 1: 0.702724506855011\n",
      "Epoch 2: 100%|██████████| 477/477 [01:12<00:00,  6.62it/s, v_num=86, c0_loss=0.0068, s_loss=0.00683] \n",
      "validation dice loss in epoch 2: 0.6438850665092468\n",
      "validation bce loss in epoch 2: 0.4031966245174408\n",
      "Epoch 3: 100%|██████████| 477/477 [01:11<00:00,  6.63it/s, v_num=86, c0_loss=0.00547, s_loss=0.00546]\n",
      "validation dice loss in epoch 3: 0.5918426609039307\n",
      "validation bce loss in epoch 3: 0.4646360540390015\n",
      "Epoch 4: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.0032, s_loss=0.0032]  \n",
      "validation dice loss in epoch 4: 0.5475327563285828\n",
      "validation bce loss in epoch 4: 0.41400294184684755\n",
      "Epoch 5: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.00395, s_loss=0.00395]\n",
      "validation dice loss in epoch 5: 0.5416630172729492\n",
      "validation bce loss in epoch 5: 0.41248470425605777\n",
      "Epoch 6: 100%|██████████| 477/477 [01:12<00:00,  6.62it/s, v_num=86, c0_loss=0.0028, s_loss=0.0028]  \n",
      "validation dice loss in epoch 6: 0.5521229958534241\n",
      "validation bce loss in epoch 6: 0.462740923166275\n",
      "Epoch 7: 100%|██████████| 477/477 [01:12<00:00,  6.59it/s, v_num=86, c0_loss=0.00251, s_loss=0.0025] \n",
      "validation dice loss in epoch 7: 0.5286618351936341\n",
      "validation bce loss in epoch 7: 0.4623001146316528\n",
      "Epoch 8: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.00266, s_loss=0.00265]\n",
      "validation dice loss in epoch 8: 0.5238834071159363\n",
      "validation bce loss in epoch 8: 0.45829374313354493\n",
      "Epoch 9: 100%|██████████| 477/477 [01:12<00:00,  6.59it/s, v_num=86, c0_loss=0.00141, s_loss=0.00141]  \n",
      "validation dice loss in epoch 9: 0.43461945056915285\n",
      "validation bce loss in epoch 9: 0.39866047620773315\n",
      "Epoch 10: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.00105, s_loss=0.00105]  \n",
      "validation dice loss in epoch 10: 0.4244090807437897\n",
      "validation bce loss in epoch 10: 0.43305222034454344\n",
      "Epoch 11: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.00108, s_loss=0.00108]  \n",
      "validation dice loss in epoch 11: 0.43398071646690367\n",
      "validation bce loss in epoch 11: 0.5555907487869263\n",
      "Epoch 12: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.000713, s_loss=0.000713]\n",
      "validation dice loss in epoch 12: 0.39906480312347414\n",
      "validation bce loss in epoch 12: 0.5086607456207275\n",
      "Epoch 13: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.00101, s_loss=0.00101]  \n",
      "validation dice loss in epoch 13: 0.38766124606132507\n",
      "validation bce loss in epoch 13: 0.6075835525989532\n",
      "Epoch 14: 100%|██████████| 477/477 [01:12<00:00,  6.59it/s, v_num=86, c0_loss=0.000464, s_loss=0.000464]\n",
      "validation dice loss in epoch 14: 0.37176542401313784\n",
      "validation bce loss in epoch 14: 0.7854690003395081\n",
      "Epoch 15: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.000706, s_loss=0.000706]\n",
      "validation dice loss in epoch 15: 0.4227274572849274\n",
      "validation bce loss in epoch 15: 0.8826524233818054\n",
      "Epoch 16: 100%|██████████| 477/477 [01:12<00:00,  6.59it/s, v_num=86, c0_loss=0.000535, s_loss=0.000535]\n",
      "validation dice loss in epoch 16: 0.4027127361297607\n",
      "validation bce loss in epoch 16: 0.931492383480072\n",
      "Epoch 17: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.0005, s_loss=0.0005]    \n",
      "validation dice loss in epoch 17: 0.39817061185836794\n",
      "validation bce loss in epoch 17: 1.0964219665527344\n",
      "Epoch 18: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.000403, s_loss=0.000403]\n",
      "validation dice loss in epoch 18: 0.3992212176322937\n",
      "validation bce loss in epoch 18: 1.1467055821418761\n",
      "Epoch 19: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.000815, s_loss=0.000815]\n",
      "validation dice loss in epoch 19: 0.3932387089729309\n",
      "validation bce loss in epoch 19: 1.1248324060440062\n",
      "Epoch 20: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.00044, s_loss=0.00044]  \n",
      "validation dice loss in epoch 20: 0.416697758436203\n",
      "validation bce loss in epoch 20: 1.551350703239441\n",
      "Epoch 21: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.00053, s_loss=0.00053]  \n",
      "validation dice loss in epoch 21: 0.42449983716011047\n",
      "validation bce loss in epoch 21: 1.3809627485275269\n",
      "Epoch 22: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.000502, s_loss=0.000502]\n",
      "validation dice loss in epoch 22: 0.3880062568187714\n",
      "validation bce loss in epoch 22: 1.5592543697357177\n",
      "Epoch 23: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.000343, s_loss=0.000343]\n",
      "validation dice loss in epoch 23: 0.37927822828292845\n",
      "validation bce loss in epoch 23: 1.408079514503479\n",
      "Epoch 24: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.000409, s_loss=0.000409]\n",
      "validation dice loss in epoch 24: 0.3802984535694122\n",
      "validation bce loss in epoch 24: 1.5151008653640747\n",
      "Epoch 25: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.000335, s_loss=0.000335]\n",
      "validation dice loss in epoch 25: 0.3577453410625458\n",
      "validation bce loss in epoch 25: 1.5904268789291383\n",
      "Epoch 26: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.000376, s_loss=0.000376]\n",
      "validation dice loss in epoch 26: 0.3350245499610901\n",
      "validation bce loss in epoch 26: 1.7684759616851806\n",
      "Epoch 27: 100%|██████████| 477/477 [01:12<00:00,  6.59it/s, v_num=86, c0_loss=0.000218, s_loss=0.000218]\n",
      "validation dice loss in epoch 27: 0.34423344016075136\n",
      "validation bce loss in epoch 27: 1.9386569881439208\n",
      "Epoch 28: 100%|██████████| 477/477 [01:12<00:00,  6.58it/s, v_num=86, c0_loss=0.000367, s_loss=0.000367]\n",
      "validation dice loss in epoch 28: 0.33781699776649476\n",
      "validation bce loss in epoch 28: 1.9733956050872803\n",
      "Epoch 29: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.000221, s_loss=0.000221]\n",
      "validation dice loss in epoch 29: 0.3376750326156616\n",
      "validation bce loss in epoch 29: 1.9905969858169557\n",
      "Epoch 30: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.000271, s_loss=0.000271]\n",
      "validation dice loss in epoch 30: 0.3433297300338745\n",
      "validation bce loss in epoch 30: 2.009574670791626\n",
      "Epoch 31: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.00038, s_loss=0.00038]  \n",
      "validation dice loss in epoch 31: 0.33968764781951905\n",
      "validation bce loss in epoch 31: 2.0919750213623045\n",
      "Epoch 32: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.000367, s_loss=0.000367]\n",
      "validation dice loss in epoch 32: 0.3306088030338287\n",
      "validation bce loss in epoch 32: 2.317472414970398\n",
      "Epoch 33: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.00027, s_loss=0.00027]  \n",
      "validation dice loss in epoch 33: 0.35706558942794797\n",
      "validation bce loss in epoch 33: 2.4781385374069216\n",
      "Epoch 34: 100%|██████████| 477/477 [01:12<00:00,  6.59it/s, v_num=86, c0_loss=0.000228, s_loss=0.000228]\n",
      "validation dice loss in epoch 34: 0.3607166826725006\n",
      "validation bce loss in epoch 34: 2.5542539310455323\n",
      "Epoch 35: 100%|██████████| 477/477 [01:12<00:00,  6.59it/s, v_num=86, c0_loss=0.000298, s_loss=0.000299]\n",
      "validation dice loss in epoch 35: 0.3589435279369354\n",
      "validation bce loss in epoch 35: 2.3838049221038817\n",
      "Epoch 36: 100%|██████████| 477/477 [01:12<00:00,  6.61it/s, v_num=86, c0_loss=0.000294, s_loss=0.000294]\n",
      "validation dice loss in epoch 36: 0.35594035625457765\n",
      "validation bce loss in epoch 36: 2.633966579437256\n",
      "Epoch 37: 100%|██████████| 477/477 [01:12<00:00,  6.59it/s, v_num=86, c0_loss=0.00024, s_loss=0.00024]  \n",
      "validation dice loss in epoch 37: 0.352349009513855\n",
      "validation bce loss in epoch 37: 2.6812705898284914\n",
      "Epoch 38: 100%|██████████| 477/477 [01:12<00:00,  6.60it/s, v_num=86, c0_loss=0.000295, s_loss=0.000295]\n",
      "validation dice loss in epoch 38: 0.338573477268219\n",
      "validation bce loss in epoch 38: 2.611296396255493\n",
      "Epoch 39: 100%|██████████| 477/477 [01:12<00:00,  6.59it/s, v_num=86, c0_loss=0.000415, s_loss=0.000415]\n",
      "validation dice loss in epoch 39: 0.3492535102367401\n",
      "validation bce loss in epoch 39: 2.7386354541778566\n",
      "Epoch 39: 100%|██████████| 477/477 [01:14<00:00,  6.43it/s, v_num=86, c0_loss=0.000415, s_loss=0.000415]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=40` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 477/477 [01:14<00:00,  6.42it/s, v_num=86, c0_loss=0.000415, s_loss=0.000415]\n"
     ]
    }
   ],
   "source": [
    "model= GAN(num_classes=3, lr= 0.0003)\n",
    "torch.manual_seed(2023)\n",
    "trainer = pl.Trainer(max_epochs=40, devices=[1])\n",
    "early_stopping= EarlyStopping(monitor=\"dice loss\", mode= 'max', patience=3)\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance log\n",
    "\n",
    "epoch 17 \n",
    "dice= 0.559\n",
    "c_loss = 0.00059, s_loss= 0.00059\n",
    "\n",
    "version = 53 \\\n",
    "dice loss= 0.614 \\\n",
    "c_loss = 0.0028 s_loss= 0.0032 \n",
    "\n",
    "version = 57 \\\n",
    "dice= 0.7\\\n",
    "c_loss= 0.011, s_loss= 0.00367\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_from_checkpoint(checkpoint_path=checkpoint_path)\n",
    "model.cuda()\n",
    "# model= model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loader= get_test_data(TRAIN_IMG_DIR, TRAIN_MASK_DIR, BATCH_SIZE, \n",
    "                           test_transform=None, \n",
    "                           num_workers=NUM_WORKERS, \n",
    "                           pin_memory=PIN_MEMORY)\n",
    "\n",
    "with Path(\"/home/haobo/HaoboSeg-pytorch/eizzaty/\"):\n",
    "    if not os.path.exists(model_category):\n",
    "        print(model_category + \" does not exist. Creating directory...\")\n",
    "        os.makedirs(model_category)\n",
    "        print(model_category+ \" created!\")\n",
    "\n",
    "    for j, (inputs, masks, file_names) in enumerate(test_loader):\n",
    "\n",
    "        inputs, masks= inputs.cuda(), masks.cuda()\n",
    "\n",
    "        pred= model(inputs)\n",
    "        pred= torch.sigmoid(pred)\n",
    "        pred = pred.cpu().detach().numpy()\n",
    "        ori_imgs = inputs.cpu().detach().numpy()\n",
    "        ground_truth = masks.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        if not os.path.exists(model_category+\"/predicted_images\"):\n",
    "            print(model_category+\"/predicted_images\" + \" does not exist. Creating directory...\")\n",
    "            os.makedirs(model_category+\"/predicted_images\")\n",
    "            print(model_category+\"/predicted_images\"+ \" created!\")\n",
    "        \n",
    "        if not os.path.exists(model_category+\"/original_images\"):\n",
    "            print(model_category+\"/original_images\" + \" does not exist. Creating directory...\")\n",
    "            os.makedirs(model_category+\"/original_images\")\n",
    "            print(model_category+\"/original_images\"+ \" created!\")\n",
    "\n",
    "        if not os.path.exists(model_category+\"/groundtruth_images\"):\n",
    "            print(model_category+\"/groundtruth_images\" + \" does not exist. Creating directory...\")\n",
    "            os.makedirs(model_category+\"/groundtruth_images\")\n",
    "            print(model_category+\"/groundtruth_images\"+ \" created!\")\n",
    "        \n",
    "\n",
    "        for i in range(inputs.size(0)):\n",
    "            ground_truth_final= np.argmax(np.transpose(ground_truth[i].reshape(3, IMAGE_HEIGHT, IMAGE_WIDTH), (1,2,0)), axis=2)\n",
    "            pred_final= np.argmax(np.transpose(pred[i].reshape(3, IMAGE_HEIGHT, IMAGE_WIDTH), (1,2,0)), axis=2)\n",
    "            cv2.imwrite(model_category+\"/groundtruth_images/\"+Path(file_names[i]).stem + \"_groundtruth.png\", 100*ground_truth_final)\n",
    "            cv2.imwrite(model_category+\"/predicted_images/\"+Path(file_names[i]).stem + \"_pred.png\", 100*pred_final)\n",
    "            cv2.imwrite(model_category+\"/original_images/\"+Path(file_names[i]).stem + \"_ori.png\", 255*ori_imgs[i].reshape(IMAGE_HEIGHT, IMAGE_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
