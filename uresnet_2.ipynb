{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "# from albumentations import HorizontalFlip\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from collections import defaultdict\n",
    "import os, time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score, confusion_matrix\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from path import Path\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "print(device)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:\n",
      "Train images: 3813\t Train masks: 3813\n",
      "Val images: 195\t Val masks: 195\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE= 1e-3\n",
    "BATCH_SIZE= 4\n",
    "NUM_EPOCHS= 10\n",
    "NUM_WORKERS= 0\n",
    "\n",
    "IMAGE_HEIGHT= 512\n",
    "IMAGE_WIDTH= 416\n",
    "PIN_MEMORY= True\n",
    "LOAD_MODEL= False\n",
    "\n",
    "num_block= [3, 4, 6, 3];\n",
    "input_channel=3 \n",
    "\n",
    "model_category = 'uresnet'\n",
    "checkpoint_path = 'uresnet.pth'\n",
    "training_checkpoint = 'training_checkpoint.pth'\n",
    "\n",
    "TRAIN_IMG_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/train_f/*\"))\n",
    "TRAIN_MASK_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/train_m/*\"))\n",
    "\n",
    "VAL_IMG_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/val_f/*\"))\n",
    "VAL_MASK_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/val_m/*\"))\n",
    "\n",
    "data_str = f\"Dataset Size:\\nTrain images: {len(TRAIN_IMG_DIR)}\\t Train masks: {len(TRAIN_MASK_DIR)}\"\n",
    "print(data_str)\n",
    "\n",
    "data_str = f\"Val images: {len(VAL_IMG_DIR)}\\t Val masks: {len(VAL_MASK_DIR)}\"\n",
    "print(data_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EchoDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "        image = image/image.max()\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)        \n",
    "        mask = cv2.resize(mask, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "        masks = [(mask==c) for c in range(3)]\n",
    "        mask = np.stack(masks, axis=0)\n",
    "        mask = mask.astype(np.float32)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentation= self.transform(image= image, mask= mask)\n",
    "            image = augmentation['image']\n",
    "            mask = augmentation['mask']\n",
    "\n",
    "            # image = np.transpose(image, (1,2,0)).to(torch.float32)\n",
    "            # mask = mask.to(torch.float32)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomGamma(gamma_limit= 70,p=0.6)\n",
    "\n",
    "])\n",
    "\n",
    "def get_train_data(train_img_dir, train_mask_dir, val_img_dir, val_mask_dir, batch_size, train_transform, val_transform, num_workers, pin_memory):\n",
    "    train_ds= EchoDataset(train_img_dir, train_mask_dir, train_transform)\n",
    "    train_dataloader= DataLoader(train_ds, batch_size=batch_size,\n",
    "                                 shuffle=True, \n",
    "                                 num_workers=num_workers,\n",
    "                                 pin_memory=pin_memory)\n",
    "    val_ds= EchoDataset(val_img_dir, val_mask_dir, val_transform)\n",
    "    val_dataloader= DataLoader(val_ds, batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               num_workers=num_workers,\n",
    "                               pin_memory=pin_memory)\n",
    "\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "def get_test_data(test_img_dir, test_mask_dir, batch_size, test_transform, num_workers, pin_memory):\n",
    "    test_ds= EchoDataset(test_img_dir, test_mask_dir, test_transform)\n",
    "    test_dataloader= DataLoader(test_ds, batch_size=batch_size,\n",
    "                                shuffle= False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=pin_memory) \n",
    "    return test_dataloader\n",
    "\n",
    "\n",
    "# train_ds= EchoDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform)\n",
    "# print(ds[1][0].dtype)\n",
    "train_dataloader, val_dataloader = get_train_data(train_img_dir= TRAIN_IMG_DIR, train_mask_dir= TRAIN_MASK_DIR, \n",
    "                                                  val_img_dir= VAL_IMG_DIR, val_mask_dir= VAL_MASK_DIR, \n",
    "                                                  train_transform=None, val_transform=None,\n",
    "                                                  batch_size= BATCH_SIZE, \n",
    "                                                  num_workers= NUM_WORKERS, \n",
    "                                                  pin_memory= PIN_MEMORY)\n",
    "\n",
    "len(train_dataloader)\n",
    "\n",
    "# for i , data in enumerate(train_dataloader):\n",
    "#     inputs, mask= data\n",
    "#     print(inputs.dtype)\n",
    "                        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 512)\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "y_pred=np.random.randn(BATCH_SIZE,IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "y_true=np.random.randn(BATCH_SIZE,IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "loss= 1-((2*sum(y_pred.flatten()*y_true.flatten()))/(sum(y_pred**2) + sum(y_true**2) + 1))\n",
    "print(loss.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= torch.randn((BATCH_SIZE, 3, IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "true= torch.randn((BATCH_SIZE, 3, IMAGE_WIDTH, IMAGE_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0338)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dice_loss1(y_pred, y_true):\n",
    "    #flatten label and prediction tensors\n",
    "    smooth = 1.\n",
    "    y_pred= y_pred.view(-1)\n",
    "    y_true= y_true.view(-1)\n",
    "    \n",
    "    intersection = (y_pred*y_true).sum()\n",
    "    dice = (2*intersection + smooth) / (y_pred.sum() + y_pred.sum() + smooth)\n",
    "    return (1 - dice)/BATCH_SIZE\n",
    "    \n",
    "\n",
    "dice_loss1(pred, true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target):\n",
    "    smooth = 1.\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def combo_loss(pred, target, bce_weight=0.5):\n",
    "    pred= torch.sigmoid(pred)\n",
    "\n",
    "    dice = dice_loss(pred, target)\n",
    "\n",
    "    bce= F.binary_cross_entropy(pred, target)\n",
    "\n",
    "    loss = bce*bce_weight + dice*(1-bce_weight)\n",
    "\n",
    "    return dice, bce, loss\n",
    "\n",
    "# dice, bce, loss= combo_loss(pred, true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name= \"resnet34\",\n",
    "    encoder_weights= \"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, optimizer, scheduler, num_epochs, tb_writer):\n",
    "\n",
    "    # training session\n",
    "    best_vloss= 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # print('--'*50)\n",
    "        # print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "        # print('--'*50)\n",
    "        since= time.time()\n",
    "        model.train(True)\n",
    "        running_loss, running_dice_loss, running_bce_loss=0, 0, 0\n",
    "        samples_per_epoch=0\n",
    "        with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n",
    "            for inputs, masks in tepoch:\n",
    "                # print(inputs.shape)\n",
    "                inputs, masks= inputs.cuda(), masks.cuda()\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                dice, bce, loss = combo_loss(outputs, masks)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_dice_loss += dice.item() * inputs.size(0)\n",
    "                running_bce_loss += bce.item() * inputs.size(0)\n",
    "                samples_per_epoch += inputs.size(0)\n",
    "                torch.save(model.state_dict(), training_checkpoint)\n",
    "                tepoch.set_postfix(loss= running_loss/samples_per_epoch)\n",
    "                # print('saved!')\n",
    "        \n",
    "        avg_train_loss = running_loss/samples_per_epoch\n",
    "        avg_dice_loss = running_dice_loss/samples_per_epoch\n",
    "        avg_bce_loss = running_bce_loss/samples_per_epoch\n",
    "\n",
    "        model.train(False)\n",
    "\n",
    "        running_vloss,running_val_dice, running_val_bce = 0, 0, 0\n",
    "        for index, data in enumerate(val_dataloader):\n",
    "            inputs, masks= data\n",
    "            inputs, masks= inputs.cuda(), masks.cuda()\n",
    "            outputs = model(inputs)\n",
    "            val_dice, val_bce, val_loss= combo_loss(outputs, masks)\n",
    "            running_vloss+=val_loss.item()\n",
    "            running_val_dice += val_dice.item()\n",
    "            running_val_bce += val_bce.item()\n",
    "            \n",
    "        \n",
    "        avg_val_loss = running_vloss / (index+1)\n",
    "        avg_val_dice = running_val_dice / (index+1)\n",
    "        avg_val_bce  = running_val_bce / (index+1) \n",
    "\n",
    "        time_elapsed= time.time()-since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print(\"Train: bce:{}\\t dice:{}\\t loss:{}\\t\".format(avg_bce_loss,avg_dice_loss, avg_train_loss))\n",
    "        print(\"Validation: bce:{}\\t dice:{}\\t loss:{}\\t\".format(avg_val_bce, avg_val_dice, avg_val_loss))\n",
    "        scheduler.step()\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(\"LR\", param_group['lr'])\n",
    "\n",
    "        tb_writer.add_scalars('Training vs. Validation Loss', {'Training':avg_train_loss, 'Validation': avg_val_loss}, epoch+1)\n",
    "        # tb_writer.flush()\n",
    "\n",
    "        if avg_val_loss < best_vloss:\n",
    "            print('Validation loss improved from {:.4f} to {:.4f}. Model is saved to {}'.format(best_vloss, avg_val_loss, checkpoint_path))\n",
    "            best_vloss= avg_val_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 954/954 [02:54<00:00,  5.47batch/s, loss=0.103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 57s\n",
      "Train: bce:0.06445967904303038\t dice:0.1406528678835767\t loss:0.10255627341543068\t\n",
      "Validation: bce:0.07896328740278069\t dice:0.13382861291875645\t loss:0.10639594951454474\t\n",
      "LR 0.001\n",
      "Validation loss improved from 10000000000.0000 to 0.1064. Model is saved to uresnet.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 954/954 [02:55<00:00,  5.45batch/s, loss=0.0508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 57s\n",
      "Train: bce:0.030076189761419105\t dice:0.07158043605822326\t loss:0.05082831295134357\t\n",
      "Validation: bce:0.12958709880405542\t dice:0.17987274424153932\t loss:0.15472992175087638\t\n",
      "LR 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 954/954 [02:56<00:00,  5.42batch/s, loss=0.0441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 58s\n",
      "Train: bce:0.026018484153875428\t dice:0.06213038335189149\t loss:0.04407443377584289\t\n",
      "Validation: bce:0.09741402189342344\t dice:0.13064952757285567\t loss:0.11403177465711321\t\n",
      "LR 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 954/954 [02:55<00:00,  5.43batch/s, loss=0.034] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 58s\n",
      "Train: bce:0.019804426738315763\t dice:0.04825415895651433\t loss:0.03402929290163839\t\n",
      "Validation: bce:0.11805597076914748\t dice:0.14586446343027815\t loss:0.131960217821963\t\n",
      "LR 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 954/954 [02:55<00:00,  5.42batch/s, loss=0.0321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 58s\n",
      "Train: bce:0.018813348134186773\t dice:0.045330610686076335\t loss:0.03207197946093541\t\n",
      "Validation: bce:0.1378153550381563\t dice:0.15163366785463023\t loss:0.1447245119785776\t\n",
      "LR 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 954/954 [02:55<00:00,  5.44batch/s, loss=0.0286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 58s\n",
      "Train: bce:0.01670738137963404\t dice:0.040485385706691704\t loss:0.028596383564168312\t\n",
      "Validation: bce:0.13176966641022234\t dice:0.1751652487686702\t loss:0.1534674569052093\t\n",
      "LR 0.00025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 954/954 [02:56<00:00,  5.39batch/s, loss=0.0233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 59s\n",
      "Train: bce:0.013595891778264268\t dice:0.03294556174664681\t loss:0.02327072679109377\t\n",
      "Validation: bce:0.15272864235603079\t dice:0.14650753125244256\t loss:0.1496180864621182\t\n",
      "LR 0.00025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 954/954 [02:56<00:00,  5.40batch/s, loss=0.0207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 59s\n",
      "Train: bce:0.012159199919917985\t dice:0.02933244230438179\t loss:0.02074582110665428\t\n",
      "Validation: bce:0.1721929523105524\t dice:0.15956994389392892\t loss:0.16588144977481997\t\n",
      "LR 0.00025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 954/954 [02:56<00:00,  5.41batch/s, loss=0.0193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 58s\n",
      "Train: bce:0.011316811834424617\t dice:0.02736202461135503\t loss:0.019339418215073845\t\n",
      "Validation: bce:0.17332549879745562\t dice:0.1534044075073028\t loss:0.1633649533804582\t\n",
      "LR 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 954/954 [02:56<00:00,  5.42batch/s, loss=0.0161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 58s\n",
      "Train: bce:0.009347080541034555\t dice:0.022886620630277382\t loss:0.016116850572955005\t\n",
      "Validation: bce:0.18842689312842428\t dice:0.1541744044848851\t loss:0.171300649338839\t\n",
      "LR 0.000125\n",
      "Total time taken: 29m 40s\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS=10\n",
    "since= time.time()\n",
    "timestamp= datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/smp_uresnet_{}'.format(timestamp))\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name= \"resnet34\",\n",
    "    encoder_weights= \"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3,\n",
    ").cuda()\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.5)\n",
    "# model.load_state_dict(torch.load(training_checkpoint))\n",
    "model= train_network(model, optimizer_ft, exp_lr_scheduler, num_epochs=NUM_EPOCHS, tb_writer=writer).cuda()\n",
    "writer.close()\n",
    "time_elapsed= time.time() - since\n",
    "print('Total time taken: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('uresnet.pth'))\n",
    "model= model.cuda()\n",
    "\n",
    "test_loader= get_test_data(TRAIN_IMG_DIR, TRAIN_MASK_DIR, BATCH_SIZE, \n",
    "                           test_transform=None, \n",
    "                           num_workers=NUM_WORKERS, \n",
    "                           pin_memory=PIN_MEMORY)\n",
    "\n",
    "for i, data in enumerate(test_loader):\n",
    "    inputs, masks= data\n",
    "    inputs, masks= inputs.cuda(), masks.cuda()\n",
    "\n",
    "    outputs= model(inputs)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
