{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "# from albumentations import HorizontalFlip\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from collections import defaultdict\n",
    "import os, time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score, confusion_matrix\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from path import Path\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "print(device)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE= 1e-3\n",
    "BATCH_SIZE= 4\n",
    "NUM_EPOCHS= 10\n",
    "NUM_WORKERS= 0\n",
    "\n",
    "IMAGE_HEIGHT= 512\n",
    "IMAGE_WIDTH= 416\n",
    "PIN_MEMORY= True\n",
    "LOAD_MODEL= False\n",
    "\n",
    "num_block= [3, 4, 6, 3];\n",
    "input_channel=3 \n",
    "\n",
    "model_category = 'uresnet'\n",
    "checkpoint_path = 'uresnet.pth'\n",
    "training_checkpoint = 'training_checkpoint.pth'\n",
    "\n",
    "TRAIN_IMG_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/train_f/*\"))\n",
    "TRAIN_MASK_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/train_m/*\"))\n",
    "\n",
    "VAL_IMG_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/val_f/*\"))\n",
    "VAL_MASK_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/val_m/*\"))\n",
    "\n",
    "data_str = f\"Dataset Size:\\nTrain images: {len(TRAIN_IMG_DIR)}\\t Train masks: {len(TRAIN_MASK_DIR)}\"\n",
    "print(data_str)\n",
    "\n",
    "data_str = f\"Val images: {len(VAL_IMG_DIR)}\\t Val masks: {len(VAL_MASK_DIR)}\"\n",
    "print(data_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchoDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "        image = image/image.max()\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)        \n",
    "        mask = cv2.resize(mask, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "        masks = [(mask==c) for c in range(3)]\n",
    "        mask = np.stack(masks, axis=0)\n",
    "        mask = mask.astype(np.float32)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentation= self.transform(image= image, mask= mask)\n",
    "            image = augmentation['image']\n",
    "            mask = augmentation['mask']\n",
    "\n",
    "            # image = np.transpose(image, (1,2,0)).to(torch.float32)\n",
    "            # mask = mask.to(torch.float32)\n",
    "\n",
    "        return image, mask, self.images_path[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomGamma(gamma_limit= 70,p=0.6)\n",
    "\n",
    "])\n",
    "\n",
    "def get_train_data(train_img_dir, train_mask_dir, val_img_dir, val_mask_dir, batch_size, train_transform, val_transform, num_workers, pin_memory):\n",
    "    train_ds= EchoDataset(train_img_dir, train_mask_dir, train_transform)\n",
    "    train_dataloader= DataLoader(train_ds, batch_size=batch_size,\n",
    "                                 shuffle=True, \n",
    "                                 num_workers=num_workers,\n",
    "                                 pin_memory=pin_memory)\n",
    "    val_ds= EchoDataset(val_img_dir, val_mask_dir, val_transform)\n",
    "    val_dataloader= DataLoader(val_ds, batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               num_workers=num_workers,\n",
    "                               pin_memory=pin_memory)\n",
    "\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "def get_test_data(test_img_dir, test_mask_dir, batch_size, test_transform, num_workers, pin_memory):\n",
    "    test_ds= EchoDataset(test_img_dir, test_mask_dir, test_transform)\n",
    "    test_dataloader= DataLoader(test_ds, batch_size=batch_size,\n",
    "                                shuffle= False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=pin_memory) \n",
    "    return test_dataloader\n",
    "\n",
    "\n",
    "# train_ds= EchoDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform)\n",
    "# print(ds[1][0].dtype)\n",
    "train_dataloader, val_dataloader = get_train_data(train_img_dir= TRAIN_IMG_DIR, train_mask_dir= TRAIN_MASK_DIR, \n",
    "                                                  val_img_dir= VAL_IMG_DIR, val_mask_dir= VAL_MASK_DIR, \n",
    "                                                  train_transform=None, val_transform=None,\n",
    "                                                  batch_size= BATCH_SIZE, \n",
    "                                                  num_workers= NUM_WORKERS, \n",
    "                                                  pin_memory= PIN_MEMORY)\n",
    "\n",
    "len(train_dataloader)\n",
    "\n",
    "# for i , data in enumerate(train_dataloader):\n",
    "#     inputs, mask= data\n",
    "#     print(inputs.dtype)\n",
    "                        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "y_pred=np.random.randn(BATCH_SIZE,IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "y_true=np.random.randn(BATCH_SIZE,IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "loss= 1-((2*sum(y_pred.flatten()*y_true.flatten()))/(sum(y_pred**2) + sum(y_true**2) + 1))\n",
    "print(loss.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= torch.randn((BATCH_SIZE, 3, IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "true= torch.randn((BATCH_SIZE, 3, IMAGE_WIDTH, IMAGE_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss1(y_pred, y_true):\n",
    "    #flatten label and prediction tensors\n",
    "    smooth = 1.\n",
    "    y_pred= y_pred.view(-1)\n",
    "    y_true= y_true.view(-1)\n",
    "    \n",
    "    intersection = (y_pred*y_true).sum()\n",
    "    dice = (2*intersection + smooth) / (y_pred.sum() + y_pred.sum() + smooth)\n",
    "    return (1 - dice)/BATCH_SIZE\n",
    "    \n",
    "\n",
    "dice_loss1(pred, true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target):\n",
    "    smooth = 1.\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def combo_loss(pred, target, bce_weight=0.5):\n",
    "    pred= torch.sigmoid(pred)\n",
    "\n",
    "    dice = dice_loss(pred, target)\n",
    "\n",
    "    bce= F.binary_cross_entropy(pred, target)\n",
    "\n",
    "    loss = bce*bce_weight + dice*(1-bce_weight)\n",
    "\n",
    "    return dice, bce, loss\n",
    "\n",
    "# dice, bce, loss= combo_loss(pred, true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name= \"resnet34\",\n",
    "    encoder_weights= \"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, optimizer, scheduler, num_epochs, tb_writer):\n",
    "\n",
    "    # training session\n",
    "    best_vloss= 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # print('--'*50)\n",
    "        # print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "        # print('--'*50)\n",
    "        since= time.time()\n",
    "        model.train(True)\n",
    "        running_loss, running_dice_loss, running_bce_loss=0, 0, 0\n",
    "        samples_per_epoch=0\n",
    "        with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n",
    "            for inputs, masks in tepoch:\n",
    "                # print(inputs.shape)\n",
    "                inputs, masks= inputs.cuda(), masks.cuda()\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                dice, bce, loss = combo_loss(outputs, masks)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_dice_loss += dice.item() * inputs.size(0)\n",
    "                running_bce_loss += bce.item() * inputs.size(0)\n",
    "                samples_per_epoch += inputs.size(0)\n",
    "                torch.save(model.state_dict(), training_checkpoint)\n",
    "                tepoch.set_postfix(loss= running_loss/samples_per_epoch)\n",
    "                # print('saved!')\n",
    "        \n",
    "        avg_train_loss = running_loss/samples_per_epoch\n",
    "        avg_dice_loss = running_dice_loss/samples_per_epoch\n",
    "        avg_bce_loss = running_bce_loss/samples_per_epoch\n",
    "\n",
    "        model.train(False)\n",
    "\n",
    "        running_vloss,running_val_dice, running_val_bce = 0, 0, 0\n",
    "        for index, data in enumerate(val_dataloader):\n",
    "            inputs, masks= data\n",
    "            inputs, masks= inputs.cuda(), masks.cuda()\n",
    "            outputs = model(inputs)\n",
    "            val_dice, val_bce, val_loss= combo_loss(outputs, masks)\n",
    "            running_vloss+=val_loss.item()\n",
    "            running_val_dice += val_dice.item()\n",
    "            running_val_bce += val_bce.item()\n",
    "            \n",
    "        \n",
    "        avg_val_loss = running_vloss / (index+1)\n",
    "        avg_val_dice = running_val_dice / (index+1)\n",
    "        avg_val_bce  = running_val_bce / (index+1) \n",
    "\n",
    "        time_elapsed= time.time()-since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print(\"Train: bce:{}\\t dice:{}\\t loss:{}\\t\".format(avg_bce_loss,avg_dice_loss, avg_train_loss))\n",
    "        print(\"Validation: bce:{}\\t dice:{}\\t loss:{}\\t\".format(avg_val_bce, avg_val_dice, avg_val_loss))\n",
    "        scheduler.step()\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(\"LR\", param_group['lr'])\n",
    "\n",
    "        tb_writer.add_scalars('Training vs. Validation Loss', {'Training':avg_train_loss, 'Validation': avg_val_loss}, epoch+1)\n",
    "        # tb_writer.flush()\n",
    "\n",
    "        if avg_val_loss < best_vloss:\n",
    "            print('Validation loss improved from {:.4f} to {:.4f}. Model is saved to {}'.format(best_vloss, avg_val_loss, checkpoint_path))\n",
    "            best_vloss= avg_val_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS=10\n",
    "since= time.time()\n",
    "timestamp= datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/smp_uresnet_{}'.format(timestamp))\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name= \"resnet34\",\n",
    "    encoder_weights= \"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3,\n",
    ").cuda()\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.5)\n",
    "# model.load_state_dict(torch.load(training_checkpoint))\n",
    "model= train_network(model, optimizer_ft, exp_lr_scheduler, num_epochs=NUM_EPOCHS, tb_writer=writer).cuda()\n",
    "writer.close()\n",
    "time_elapsed= time.time() - since\n",
    "print('Total time taken: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving predictions to local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('uresnet.pth'))\n",
    "model= model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loader= get_test_data(TRAIN_IMG_DIR, TRAIN_MASK_DIR, BATCH_SIZE, \n",
    "                           test_transform=None, \n",
    "                           num_workers=NUM_WORKERS, \n",
    "                           pin_memory=PIN_MEMORY)\n",
    "\n",
    "with Path(\"/home/haobo/HaoboSeg-pytorch/eizzaty/\"):\n",
    "    if not os.path.exists(model_category):\n",
    "        print(model_category + \" does not exist. Creating directory...\")\n",
    "        os.makedirs(model_category)\n",
    "        print(model_category+ \" created!\")\n",
    "\n",
    "    for j, (inputs, masks, file_names) in enumerate(test_loader):\n",
    "\n",
    "        inputs, masks= inputs.cuda(), masks.cuda()\n",
    "\n",
    "        pred= model(inputs)\n",
    "        pred= torch.sigmoid(pred)\n",
    "        pred = pred.cpu().detach().numpy()\n",
    "        ori_imgs = inputs.cpu().detach().numpy()\n",
    "        ground_truth = masks.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        if not os.path.exists(model_category+\"/predicted_images\"):\n",
    "            print(model_category+\"/predicted_images\" + \" does not exist. Creating directory...\")\n",
    "            os.makedirs(model_category+\"/predicted_images\")\n",
    "            print(model_category+\"/predicted_images\"+ \" created!\")\n",
    "        \n",
    "        if not os.path.exists(model_category+\"/original_images\"):\n",
    "            print(model_category+\"/original_images\" + \" does not exist. Creating directory...\")\n",
    "            os.makedirs(model_category+\"/original_images\")\n",
    "            print(model_category+\"/original_images\"+ \" created!\")\n",
    "\n",
    "        if not os.path.exists(model_category+\"/groundtruth_images\"):\n",
    "            print(model_category+\"/groundtruth_images\" + \" does not exist. Creating directory...\")\n",
    "            os.makedirs(model_category+\"/groundtruth_images\")\n",
    "            print(model_category+\"/groundtruth_images\"+ \" created!\")\n",
    "        \n",
    "\n",
    "        for i in range(inputs.size(0)):\n",
    "            ground_truth_final= np.argmax(np.transpose(ground_truth[i].reshape(3, IMAGE_HEIGHT, IMAGE_WIDTH), (1,2,0)), axis=2)\n",
    "            pred_final= np.argmax(np.transpose(pred[i].reshape(3, IMAGE_HEIGHT, IMAGE_WIDTH), (1,2,0)), axis=2)\n",
    "            cv2.imwrite(model_category+\"/groundtruth_images/\"+Path(file_names[i]).stem + \"_groundtruth.png\", 100*ground_truth_final)\n",
    "            cv2.imwrite(model_category+\"/predicted_images/\"+Path(file_names[i]).stem + \"_pred.png\", 100*pred_final)\n",
    "            cv2.imwrite(model_category+\"/original_images/\"+Path(file_names[i]).stem + \"_ori.png\", 255*ori_imgs[i].reshape(IMAGE_HEIGHT, IMAGE_WIDTH))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluating the predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
