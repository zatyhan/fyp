{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "# from albumentations import HorizontalFlip\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from collections import defaultdict\n",
    "import os, time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score, confusion_matrix\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "# from path import Path\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check and Use GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "print(device)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:\n",
      "Train images: 3813\t Train masks: 3813\n",
      "Val images: 195\t Val masks: 195\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE= 1e-3\n",
    "BATCH_SIZE= 4\n",
    "NUM_EPOCHS= 10\n",
    "NUM_WORKERS= 0\n",
    "\n",
    "IMAGE_HEIGHT= 512\n",
    "IMAGE_WIDTH= 416\n",
    "PIN_MEMORY= True\n",
    "LOAD_MODEL= False\n",
    "\n",
    "num_block= [3, 4, 6, 3];\n",
    "input_channel=3 \n",
    "\n",
    "model_category = 'uresnet'\n",
    "checkpoint_path = 'uresnet.pth'\n",
    "training_checkpoint = 'training_checkpoint.pth'\n",
    "\n",
    "TRAIN_IMG_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/train_f/*\"))\n",
    "TRAIN_MASK_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/train_m/*\"))\n",
    "\n",
    "VAL_IMG_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/val_f/*\"))\n",
    "VAL_MASK_DIR = sorted(glob(\"/home/haobo/HaoboSeg-pytorch/data_all/val_m/*\"))\n",
    "\n",
    "data_str = f\"Dataset Size:\\nTrain images: {len(TRAIN_IMG_DIR)}\\t Train masks: {len(TRAIN_MASK_DIR)}\"\n",
    "print(data_str)\n",
    "\n",
    "data_str = f\"Val images: {len(VAL_IMG_DIR)}\\t Val masks: {len(VAL_MASK_DIR)}\"\n",
    "print(data_str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EchoDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "        image = image/image.max()\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "        mask = cv2.imread(self.masks_path[index], cv2.IMREAD_GRAYSCALE)        \n",
    "        mask = cv2.resize(mask, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_NEAREST)\n",
    "        masks = [(mask==c) for c in range(3)]\n",
    "        mask = np.stack(masks, axis=0)\n",
    "        mask = mask.astype(np.float32)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmentation= self.transform(image= image, mask= mask)\n",
    "            image = augmentation['image']\n",
    "            mask = augmentation['mask']\n",
    "\n",
    "            # image = np.transpose(image, (1,2,0)).to(torch.float32)\n",
    "            # mask = mask.to(torch.float32)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomGamma(gamma_limit= 70,p=0.6)\n",
    "\n",
    "])\n",
    "\n",
    "def get_train_data(train_img_dir, train_mask_dir, val_img_dir, val_mask_dir, batch_size, train_transform, val_transform, num_workers, pin_memory):\n",
    "    train_ds= EchoDataset(train_img_dir, train_mask_dir, train_transform)\n",
    "    train_dataloader= DataLoader(train_ds, batch_size=batch_size,\n",
    "                                 shuffle=True, \n",
    "                                 num_workers=num_workers,\n",
    "                                 pin_memory=pin_memory)\n",
    "    val_ds= EchoDataset(val_img_dir, val_mask_dir, val_transform)\n",
    "    val_dataloader= DataLoader(val_ds, batch_size=batch_size,\n",
    "                               shuffle=False,\n",
    "                               num_workers=num_workers,\n",
    "                               pin_memory=pin_memory)\n",
    "\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "def get_test_data(test_img_dir, test_mask_dir, batch_size, test_transform, num_workers, pin_memory):\n",
    "    test_ds= EchoDataset(test_img_dir, test_mask_dir, test_transform)\n",
    "    test_dataloader= DataLoader(test_ds, batch_size=batch_size,\n",
    "                                shuffle= False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=pin_memory) \n",
    "    return test_dataloader\n",
    "\n",
    "\n",
    "# train_ds= EchoDataset(TRAIN_IMG_DIR, TRAIN_MASK_DIR, transform)\n",
    "# print(ds[1][0].dtype)\n",
    "train_dataloader, val_dataloader = get_train_data(train_img_dir= TRAIN_IMG_DIR, train_mask_dir= TRAIN_MASK_DIR, \n",
    "                                                  val_img_dir= VAL_IMG_DIR, val_mask_dir= VAL_MASK_DIR, \n",
    "                                                  train_transform=None, val_transform=None,\n",
    "                                                  batch_size= BATCH_SIZE, \n",
    "                                                  num_workers= NUM_WORKERS, \n",
    "                                                  pin_memory= PIN_MEMORY)\n",
    "\n",
    "len(train_dataloader)\n",
    "\n",
    "# for i , data in enumerate(train_dataloader):\n",
    "#     inputs, mask= data\n",
    "#     print(inputs.dtype)\n",
    "                        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 512)\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "y_pred=np.random.randn(BATCH_SIZE,IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "y_true=np.random.randn(BATCH_SIZE,IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "loss= 1-((2*sum(y_pred.flatten()*y_true.flatten()))/(sum(y_pred**2) + sum(y_true**2) + 1))\n",
    "print(loss.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= torch.randn((BATCH_SIZE, 3, IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "true= torch.randn((BATCH_SIZE, 3, IMAGE_WIDTH, IMAGE_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2211)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dice_loss1(y_pred, y_true):\n",
    "    #flatten label and prediction tensors\n",
    "    smooth = 1.\n",
    "    y_pred= y_pred.view(-1)\n",
    "    y_true= y_true.view(-1)\n",
    "    \n",
    "    intersection = (y_pred*y_true).sum()\n",
    "    dice = (2*intersection + smooth) / (y_pred.sum() + y_pred.sum() + smooth)\n",
    "    return (1 - dice)/BATCH_SIZE\n",
    "    \n",
    "\n",
    "dice_loss1(pred, true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target):\n",
    "    smooth = 1.\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def combo_loss(pred, target, bce_weight=0.5):\n",
    "    pred= torch.sigmoid(pred)\n",
    "\n",
    "    dice = dice_loss(pred, target)\n",
    "\n",
    "    bce= F.binary_cross_entropy(pred, target)\n",
    "\n",
    "    loss = bce*bce_weight + dice*(1-bce_weight)\n",
    "\n",
    "    return dice, bce, loss\n",
    "\n",
    "# dice, bce, loss= combo_loss(pred, true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name= \"resnet34\",\n",
    "    encoder_weights= \"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, optimizer, scheduler, num_epochs, tb_writer):\n",
    "\n",
    "    # training session\n",
    "    best_vloss= 1e10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # print('--'*50)\n",
    "        # print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "        # print('--'*50)\n",
    "        since= time.time()\n",
    "        model.train(True)\n",
    "        running_loss, running_dice_loss, running_bce_loss=0, 0, 0\n",
    "        samples_per_epoch=0\n",
    "        with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n",
    "            for inputs, masks in tepoch:\n",
    "                # print(inputs.shape)\n",
    "                inputs, masks= inputs.cuda(), masks.cuda()\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                dice, bce, loss = combo_loss(outputs, masks)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_dice_loss += dice.item() * inputs.size(0)\n",
    "                running_bce_loss += bce.item() * inputs.size(0)\n",
    "                samples_per_epoch += inputs.size(0)\n",
    "                torch.save(model.state_dict(), training_checkpoint)\n",
    "                tepoch.set_postfix(loss= running_loss/samples_per_epoch)\n",
    "                # print('saved!')\n",
    "        \n",
    "        avg_train_loss = running_loss/samples_per_epoch\n",
    "        avg_dice_loss = running_dice_loss/samples_per_epoch\n",
    "        avg_bce_loss = running_bce_loss/samples_per_epoch\n",
    "\n",
    "        model.train(False)\n",
    "\n",
    "        running_vloss,running_val_dice, running_val_bce = 0, 0, 0\n",
    "        for index, data in enumerate(val_dataloader):\n",
    "            inputs, masks= data\n",
    "            inputs, masks= inputs.cuda(), masks.cuda()\n",
    "            outputs = model(inputs)\n",
    "            val_dice, val_bce, val_loss= combo_loss(outputs, masks)\n",
    "            running_vloss+=val_loss.item()\n",
    "            running_val_dice += val_dice.item()\n",
    "            running_val_bce += val_bce.item()\n",
    "            \n",
    "        \n",
    "        avg_val_loss = running_vloss / (index+1)\n",
    "        avg_val_dice = running_val_dice / (index+1)\n",
    "        avg_val_bce  = running_val_bce / (index+1) \n",
    "\n",
    "        time_elapsed= time.time()-since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print(\"Train: bce:{}\\t dice:{}\\t loss:{}\\t\".format(avg_bce_loss,avg_dice_loss, avg_train_loss))\n",
    "        print(\"Validation: bce:{}\\t dice:{}\\t loss:{}\\t\".format(avg_val_bce, avg_val_dice, avg_val_loss))\n",
    "        scheduler.step()\n",
    "        for param_group in optimizer.param_groups:\n",
    "            print(\"LR\", param_group['lr'])\n",
    "\n",
    "        tb_writer.add_scalars('Training vs. Validation Loss', {'Training':avg_train_loss, 'Validation': avg_val_loss}, epoch+1)\n",
    "        # tb_writer.flush()\n",
    "\n",
    "        if avg_val_loss < best_vloss:\n",
    "            print('Validation loss improved from {:.4f} to {:.4f}. Model is saved to {}'.format(best_vloss, avg_val_loss, checkpoint_path))\n",
    "            best_vloss= avg_val_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 954/954 [02:58<00:00,  5.34batch/s, loss=0.103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 1s\n",
      "Train: bce:0.06422519604896518\t dice:0.14182896670975023\t loss:0.10302708132366886\t\n",
      "Validation: bce:0.08995215640384324\t dice:0.14646311423608235\t loss:0.11820763608022612\t\n",
      "LR 0.001\n",
      "Validation loss improved from 10000000000.0000 to 0.1182. Model is saved to uresnet.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 954/954 [02:59<00:00,  5.31batch/s, loss=0.0524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 2s\n",
      "Train: bce:0.031056597405825268\t dice:0.07375774963803094\t loss:0.05240717356735848\t\n",
      "Validation: bce:0.12122085948987883\t dice:0.15106619210267552\t loss:0.13614352625243517\t\n",
      "LR 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 954/954 [03:00<00:00,  5.30batch/s, loss=0.0444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 2s\n",
      "Train: bce:0.02610526759975653\t dice:0.06269545906286618\t loss:0.04440036332715911\t\n",
      "Validation: bce:0.08430893597554187\t dice:0.1370515183222537\t loss:0.11068022676876613\t\n",
      "LR 0.001\n",
      "Validation loss improved from 0.1182 to 0.1107. Model is saved to uresnet.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 954/954 [03:03<00:00,  5.20batch/s, loss=0.0393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 6s\n",
      "Train: bce:0.02297821466427774\t dice:0.05553446319213134\t loss:0.03925633897681015\t\n",
      "Validation: bce:0.09954844012248273\t dice:0.14007523519044018\t loss:0.11981183815063262\t\n",
      "LR 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 954/954 [03:01<00:00,  5.25batch/s, loss=0.0358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 4s\n",
      "Train: bce:0.02098293107812904\t dice:0.05067537664984144\t loss:0.03582915390843861\t\n",
      "Validation: bce:0.12032281455336785\t dice:0.15824350775504598\t loss:0.13928316031791727\t\n",
      "LR 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 954/954 [03:04<00:00,  5.18batch/s, loss=0.0316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 6s\n",
      "Train: bce:0.01848488128794137\t dice:0.04464791372414496\t loss:0.031566397481129736\t\n",
      "Validation: bce:0.11418698918150395\t dice:0.15004062713408955\t loss:0.13211380781567827\t\n",
      "LR 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 954/954 [03:02<00:00,  5.24batch/s, loss=0.0235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 4s\n",
      "Train: bce:0.013479506532929559\t dice:0.033476547494143784\t loss:0.023478026978853272\t\n",
      "Validation: bce:0.15904200411572747\t dice:0.16031894772028438\t loss:0.15968047553787426\t\n",
      "LR 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 954/954 [03:01<00:00,  5.26batch/s, loss=0.0209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 3s\n",
      "Train: bce:0.012160504387763426\t dice:0.029608306351149298\t loss:0.020884405391927298\t\n",
      "Validation: bce:0.16898009515538506\t dice:0.164026145272109\t loss:0.1665031196815627\t\n",
      "LR 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 954/954 [03:01<00:00,  5.25batch/s, loss=0.0192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 4s\n",
      "Train: bce:0.01119237329733675\t dice:0.027111346497565095\t loss:0.01915185990135891\t\n",
      "Validation: bce:0.17679110154205438\t dice:0.16403642388022677\t loss:0.17041376385153556\t\n",
      "LR 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 954/954 [03:03<00:00,  5.21batch/s, loss=0.0177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 5s\n",
      "Train: bce:0.010344668009401212\t dice:0.024980823418778633\t loss:0.01766274569503848\t\n",
      "Validation: bce:0.1933856246118643\t dice:0.16574282457633893\t loss:0.17956422649475992\t\n",
      "LR 0.0001\n",
      "Total time taken: 30m 38s\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS=10\n",
    "since= time.time()\n",
    "timestamp= datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/smp_uresnet_{}'.format(timestamp))\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name= \"resnet34\",\n",
    "    encoder_weights= \"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=3,\n",
    ").cuda()\n",
    "\n",
    "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)\n",
    "# model.load_state_dict(torch.load(training_checkpoint))\n",
    "model= train_network(model, optimizer_ft, exp_lr_scheduler, num_epochs=NUM_EPOCHS, tb_writer=writer).cuda()\n",
    "writer.close()\n",
    "time_elapsed= time.time() - since\n",
    "print('Total time taken: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
